#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Patch pour le mod√®le d'IA afin d'am√©liorer la gestion des interactions utilisateur
"""

import logging
import re
import traceback
import requests
import time
import socket
import os
import threading
import json
from typing import Dict, Any, List, Optional, Union
from pydantic import BaseModel, Field, validator
import unicodedata
import types

logger = logging.getLogger("VynalDocsAutomator.AIModelPatch")

# Ajout des fonctions utilis√©es par patch_ai_model
def _convert_form_info_to_variables(form_info):
    """
    Convertit les informations de formulaire en variables utilisables.
    
    Args:
        form_info (list): Liste des informations fournies par l'utilisateur
        
    Returns:
        dict: Dictionnaire de variables
    """
    try:
        variables = {}
        
        if not form_info:
            return variables
            
        # Analyser chaque ligne
        for info in form_info:
            # Chercher un format "cl√©: valeur"
            if ":" in info:
                key, value = info.split(":", 1)
                variables[key.strip()] = value.strip()
            # Sinon, essayer de deviner le type d'information
            else:
                info_lower = info.lower()
                if any(word in info_lower for word in ["nom", "client", "personne"]):
                    variables["nom"] = info
                elif any(word in info_lower for word in ["entreprise", "soci√©t√©", "societe", "company"]):
                    variables["entreprise"] = info
                elif any(word in info_lower for word in ["email", "mail", "courriel"]):
                    variables["email"] = info
                elif any(word in info_lower for word in ["adresse", "coordonn√©es", "coordonnees"]):
                    variables["adresse"] = info
                elif any(word in info_lower for word in ["t√©l√©phone", "telephone", "tel", "t√©l", "phone"]):
                    variables["telephone"] = info
                elif any(word in info_lower for word in ["montant", "prix", "somme", "tarif"]):
                    variables["montant"] = info
                elif any(word in info_lower for word in ["date", "jour"]):
                    variables["date"] = info
                else:
                    # Si on ne peut pas d√©terminer, utiliser un nom g√©n√©rique
                    key = f"information_{len(variables) + 1}"
                    variables[key] = info
        
        return variables
        
    except Exception as e:
        logger.error(f"Erreur dans _convert_form_info_to_variables: {e}")
        return {}

def get_model_path(instance, category, model_name):
    """
    Retourne le chemin complet d'un mod√®le.
    
    Args:
        instance: L'instance de la classe (self)
        category (str): Cat√©gorie du mod√®le
        model_name (str): Nom du mod√®le
        
    Returns:
        str: Chemin complet du mod√®le
    """
    try:
        # V√©rifier si le chemin des mod√®les est d√©fini
        if not hasattr(instance, 'models_path'):
            instance.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
        # Construire le chemin complet
        model_path = os.path.join(instance.models_path, category, model_name)
        
        # V√©rifier que le fichier existe
        if not os.path.exists(model_path):
            logger.error(f"Le mod√®le n'existe pas: {model_path}")
            return None
            
        return model_path
        
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration du chemin du mod√®le: {e}")
        return None

# Mod√®les de donn√©es avec Pydantic pour une validation stricte
class DocumentTemplate(BaseModel):
    """Mod√®le pour les templates de documents."""
    name: str = Field(...)
    category: str = Field(...)
    path: str = Field(...)
    size: int = Field(default=0)
    description: Optional[str] = Field(default="")
    variables: List[str] = Field(default_factory=list)
    
    @validator('path')
    def path_must_exist(cls, v):
        """Valide que le chemin du fichier existe."""
        if not os.path.exists(v):
            raise ValueError(f'Le chemin du fichier {v} n\'existe pas')
        return v

class ClientData(BaseModel):
    """Mod√®le pour les donn√©es client."""
    id: str = Field(default="")
    nom: str = Field(...)  # Champ obligatoire
    entreprise: Optional[str] = Field(default="")
    adresse: Optional[str] = Field(default="")
    t√©l√©phone: Optional[str] = Field(default="")
    email: Optional[str] = Field(default="")
    
    @validator('email')
    def email_must_be_valid(cls, v):
        """Valide que l'email a un format correct."""
        if v and not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', v):
            raise ValueError('Format d\'email invalide')
        return v

class ConversationContext(BaseModel):
    """Mod√®le pour le contexte de conversation."""
    state: str = Field(default="initial")
    last_action: Optional[str] = Field(default=None)
    subject: Optional[str] = Field(default=None)
    details: Dict[str, Any] = Field(default_factory=dict)
    document_type: Optional[str] = Field(default=None)
    category: Optional[str] = Field(default=None)
    model: Optional[str] = Field(default=None)
    form_info: List[str] = Field(default_factory=list)
    client: Optional[ClientData] = Field(default=None)
    available_categories: List[str] = Field(default_factory=list)
    available_models: List[str] = Field(default_factory=list)
    available_clients: List[ClientData] = Field(default_factory=list)
    state_history: List[str] = Field(default_factory=list)
    missing_vars: List[str] = Field(default_factory=list)
    current_vars: Dict[str, str] = Field(default_factory=dict)
    
    class Config:
        arbitrary_types_allowed = True

class AIResponse(BaseModel):
    """Mod√®le pour les r√©ponses de l'IA."""
    response: str = Field(...)  # Champ obligatoire
    state: str = Field(default="initial")
    action: Optional[str] = Field(default=None)

# Cr√©er une session HTTP persistante pour reduire la latence
session = requests.Session()

# Variables globales pour suivre les erreurs d'Ollama
ollama_consecutive_failures = 0
ollama_disabled_until = 0

# √âtats possibles de la conversation
STATES = {
    "initial": {
        "description": "√âtat initial de la conversation",
        "valid_transitions": ["asking_document_type", "general_query"],
        "required_context": []
    },
    "asking_document_type": {
        "description": "Demande du type de document",
        "valid_transitions": ["choosing_category", "creating_new"],
        "required_context": []
    },
    "choosing_category": {
        "description": "Choix d'une cat√©gorie de document",
        "valid_transitions": ["choosing_model"],
        "required_context": ["available_categories"]
    },
    "choosing_model": {
        "description": "Choix d'un mod√®le sp√©cifique",
        "valid_transitions": ["model_selected"],
        "required_context": ["category", "available_models"]
    },
    "model_selected": {
        "description": "Un mod√®le a √©t√© s√©lectionn√©",
        "valid_transitions": ["filling_document", "using_model"],
        "required_context": ["model"]
    },
    "filling_document": {
        "description": "Remplissage du document",
        "valid_transitions": ["document_completed", "filling_document"],
        "required_context": ["model", "form_fields"]
    },
    "creating_new": {
        "description": "Cr√©ation d'un nouveau document",
        "valid_transitions": ["document_type_selected", "creating_new"],
        "required_context": []
    }
}

def _validate_state_transition(current_state, new_state, context):
    """
    Valide une transition d'√©tat.
    
    Args:
        current_state (str): L'√©tat actuel
        new_state (str): Le nouvel √©tat demand√©
        context (dict): Le contexte actuel
        
    Returns:
        tuple: (bool, str) - (transition valide, message d'erreur)
    """
    # V√©rifier si les √©tats existent
    if current_state not in STATES:
        return False, f"√âtat actuel invalide: {current_state}"
    if new_state not in STATES:
        return False, f"Nouvel √©tat invalide: {new_state}"
        
    # V√©rifier si la transition est autoris√©e
    if new_state not in STATES[current_state]["valid_transitions"]:
        return False, f"Transition non autoris√©e de {current_state} vers {new_state}"
        
    # V√©rifier si le contexte requis est pr√©sent
    required_context = STATES[new_state]["required_context"]
    missing_context = [key for key in required_context if key not in context]
    if missing_context:
        return False, f"Contexte manquant pour {new_state}: {', '.join(missing_context)}"
        
    return True, ""

def should_use_ollama():
    """
    D√©termine si Ollama doit √™tre utilis√© en fonction des √©checs pr√©c√©dents.
    """
    global ollama_consecutive_failures, ollama_disabled_until
    
    # Si Ollama est temporairement d√©sactiv√©
    if time.time() < ollama_disabled_until:
        return False
    
    # Si trop d'√©checs cons√©cutifs, v√©rifier Ollama
    if ollama_consecutive_failures >= 3:
        if check_ollama_running():
            # R√©initialiser le compteur d'√©checs
            ollama_consecutive_failures = 0
            return True
        else:
            # D√©sactiver Ollama pendant 60 secondes
            ollama_disabled_until = time.time() + 60
            logger.warning(f"Ollama d√©sactiv√© pendant 60 secondes suite √† {ollama_consecutive_failures} √©checs cons√©cutifs")
            return False
    
    return True

def check_ollama_running(url="http://localhost:11434/api/version", timeout=2):
    """
    V√©rifie si le serveur Ollama est en cours d'ex√©cution.
    """
    try:
        response = session.get(url, timeout=timeout)
        return response.status_code == 200
    except (requests.exceptions.RequestException, socket.error):
        return False

def patch_ai_model(AIModel):
    """
    Applique les modifications au mod√®le d'IA.
    """
    original_handle_model_actions = AIModel._handle_model_actions
    original_handle_user_choice = AIModel._handle_user_choice
    
    # Sauvegarder la m√©thode originale _normalize_input si elle existe
    original_normalize_input = None
    if hasattr(AIModel, '_normalize_input'):
        original_normalize_input = AIModel._normalize_input

    def enhanced_normalize_input(self, text):
        """
        Version am√©lior√©e de _normalize_input qui normalise plus efficacement les entr√©es
        utilisateur pour une meilleure correspondance.
        """
        if not text:
            return ""
            
        # Appeler d'abord la m√©thode originale si elle existe
        if original_normalize_input:
            result = original_normalize_input(self, text)
        else:
            # Sinon, faire une normalisation de base
            result = text.lower().strip()
        
        # Normalisation suppl√©mentaire
        result = result.replace("√©", "e").replace("√®", "e").replace("√™", "e")
        result = result.replace("√†", "a").replace("√¢", "a")
        result = result.replace("√¥", "o")
        result = result.replace("√Æ", "i").replace("√Ø", "i")
        result = result.replace("√ª", "u").replace("√π", "u")
        result = result.replace("√ß", "c")
        
        # Supprimer la ponctuation et les caract√®res sp√©ciaux
        result = re.sub(r'[^\w\s]', '', result)
        
        # Remplacer les espaces multiples par un seul espace
        result = re.sub(r'\s+', ' ', result)
        
        return result.strip()

    def _show_available_categories(self):
        """
        Affiche les cat√©gories disponibles en utilisant _get_available_categories.
        """
        try:
            # Obtenir les cat√©gories disponibles
            categories = self._get_available_categories()
            
            if not categories:
                return """‚ùå Je n'ai trouv√© aucune cat√©gorie de documents.
                
Veuillez contacter l'administrateur syst√®me."""
            
            # Construire le message de r√©ponse
            response = "üìÇ Voici les cat√©gories de documents disponibles :\n\n"
            for i, category in enumerate(categories, 1):
                response += f"{i}Ô∏è‚É£ {category}\n"
            
            response += "\nVeuillez choisir une cat√©gorie en tapant son num√©ro ou son nom."
            
            # Mettre √† jour le contexte
            self.current_context["state"] = "choosing_category"
            self.current_context["last_action"] = "afficher_categories"
            self.current_context["available_categories"] = categories
            
            return response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'affichage des cat√©gories: {e}")
            logger.error(traceback.format_exc())
            return """‚ùå Une erreur s'est produite lors de la r√©cup√©ration des cat√©gories.
            
Veuillez r√©essayer ou contacter l'administrateur syst√®me."""


    def _is_simple_thanks(self, message):
        """
        V√©rifie si le message est un simple remerciement.
        """
        message = message.lower().strip()
        thanks_patterns = [
            r'^merci$',
            r'^thanks$',
            r'^thank you$'
        ]
        return any(re.match(pattern, message) for pattern in thanks_patterns)

    def _reset_context(self):
        """
        R√©initialise le contexte de conversation complet en utilisant le mod√®le Pydantic.
        """
        self.current_context = ConversationContext(
            state="initial",
            last_action="reinitialisation",
            subject=None,
            details={},
            document_type=None,
            category=None,
            model=None,
            form_info=[]
        ).dict()  # Convertir en dictionnaire pour compatibilit√© avec le code existant
        
        return self.current_context

    def _handle_state_transition(self, message, context):
        """
        G√®re une transition d'√©tat bas√©e sur le message et le contexte.
        
        Args:
            message (str): Le message de l'utilisateur
            context (dict): Le contexte actuel
            
        Returns:
            tuple: (str, dict) - (nouvel √©tat, contexte mis √† jour)
        """
        try:
            current_state = context.get("state", "initial")
            normalized_message = self._normalize_input(message)
            
            # Priorit√© sur les options 1 et 2 dans l'√©tat asking_document_type
            if current_state == "asking_document_type" and normalized_message in ["1", "2"]:
                if normalized_message == "1":
                    new_state = "choosing_category"
                    context["available_categories"] = self._get_available_categories()
                else:  # normalized_message == "2"
                    new_state = "creating_new"
                
                # Mettre √† jour l'historique des √©tats
                if "state_history" not in context:
                    context["state_history"] = []
                context["state_history"].append(current_state)
                
                # Mettre √† jour le contexte
                context["state"] = new_state
                context["last_action"] = f"transition_vers_{new_state}"
                
                return new_state, context
            
            # Commandes sp√©ciales
            if normalized_message in ["annuler", "retour", "back"]:
                state_history = context.get("state_history", [])
                if state_history:
                    new_state = state_history.pop()
                    context["state_history"] = state_history
                    return new_state, context
            
            # D√©terminer le nouvel √©tat
            new_state = current_state  # Par d√©faut, rester dans l'√©tat actuel
            
            # Transitions bas√©es sur l'√©tat actuel
            if current_state == "initial":
                if "document" in normalized_message or "modele" in normalized_message:
                    new_state = "asking_document_type"
                
            elif current_state == "asking_document_type":
                if normalized_message in ["1", "modele", "existant"]:
                    new_state = "choosing_category"
                elif normalized_message in ["2", "nouveau", "creer"]:
                    new_state = "creating_new"
                
            elif current_state == "choosing_category":
                if self._is_valid_category_choice(normalized_message, context):
                    new_state = "choosing_model"
                
            elif current_state == "choosing_model":
                if self._is_valid_model_choice(normalized_message, context):
                    new_state = "model_selected"
                
            elif current_state == "model_selected":
                if normalized_message in ["1", "remplir", "completer"]:
                    new_state = "filling_document"
                elif normalized_message in ["2", "utiliser", "tel quel"]:
                    new_state = "using_model"
            
            # Valider la transition
            is_valid, error_message = _validate_state_transition(current_state, new_state, context)
            if not is_valid:
                logger.warning(f"Transition invalide: {error_message}")
                return current_state, context
            
            # Mettre √† jour l'historique des √©tats
            if "state_history" not in context:
                context["state_history"] = []
            if new_state != current_state:
                context["state_history"].append(current_state)
            
            # Mettre √† jour le contexte
            context["state"] = new_state
            context["last_action"] = f"transition_vers_{new_state}"
            
            return new_state, context
            
        except Exception as e:
            logger.error(f"Erreur lors de la transition d'√©tat: {e}")
            return current_state, context

    def _is_valid_category_choice(self, category, context):
        """
        V√©rifie si la cat√©gorie s√©lectionn√©e est valide et met √† jour le contexte.
        """
        try:
            available_categories = context.get("available_categories", [])
            normalized_category = self._normalize_input(category)
            
            # V√©rifier si c'est un num√©ro
            if normalized_category.isdigit():
                index = int(normalized_category) - 1
                if 0 <= index < len(available_categories):
                    # Mettre √† jour le contexte avec la cat√©gorie s√©lectionn√©e
                    context["category"] = available_categories[index]
                    return True
                return False
            
            # V√©rifier si la cat√©gorie existe
            for cat in available_categories:
                if self._normalize_input(cat) == normalized_category:
                    # Mettre √† jour le contexte avec la cat√©gorie s√©lectionn√©e
                    context["category"] = cat
                    return True
            return False
            
        except Exception as e:
            logger.error(f"Erreur lors de la validation de la cat√©gorie: {e}")
            return False

    def _is_valid_model_choice(self, model, context):
        """
        V√©rifie si le mod√®le s√©lectionn√© est valide.
        """
        try:
            available_models = context.get("available_models", [])
            normalized_model = self._normalize_input(model)
            
            # V√©rifier si c'est un num√©ro
            if normalized_model.isdigit():
                index = int(normalized_model) - 1
                return 0 <= index < len(available_models)
            
            # V√©rifier si le mod√®le existe
            return any(self._normalize_input(m) == normalized_model for m in available_models)
            
        except Exception as e:
            logger.error(f"Erreur lors de la validation du mod√®le: {e}")
            return False

    def _handle_workflow(self, message, stream=False):
        """
        G√®re le workflow de conversation en fonction de l'√©tat actuel.
        """
        try:
            # Obtenir l'√©tat actuel
            current_state = self.current_context.get("state", "initial")
            
            # Debug - afficher l'√©tat actuel
            print(f"DEBUG - _handle_workflow - √âtat actuel: {current_state}")
            
            # G√©rer la transition d'√©tat
            new_state, updated_context = self._handle_state_transition(message, self.current_context)
            
            # Mettre √† jour le contexte avec le nouvel √©tat
            self.current_context = updated_context
            self.current_context["state"] = new_state
            
            # Si l'√©tat a chang√©, logger la transition
            if new_state != current_state:
                print(f"DEBUG - Transition d'√©tat effectu√©e: {current_state} -> {new_state}")
            
            # Continuer avec le traitement normal du workflow
            return self._process_current_state(message, new_state)
            
        except Exception as e:
            logger.error(f"Erreur dans _handle_workflow: {e}")
            return "Une erreur s'est produite. Veuillez r√©essayer."

    def _process_current_state(self, message, state):
        """
        Traite le message en fonction de l'√©tat actuel.
        """
        try:
            # Normaliser le message
            normalized_message = self._normalize_input(message)
            
            # Traitement en fonction de l'√©tat
            if state == "asking_document_type":
                if normalized_message == "1":
                    self.current_context["state"] = "choosing_category"
                    self.current_context["available_categories"] = self._get_available_categories()
                    return self._show_available_categories()
                elif normalized_message == "2":
                    self.current_context["state"] = "creating_new"
                    return """Pour cr√©er un nouveau document, j'ai besoin de quelques informations :

1. Quel type de document souhaitez-vous cr√©er ?
2. Quel est son objectif ?
3. Quelles informations doit-il contenir ?

Veuillez me donner ces informations."""
                else:
                    return """üìå Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document"""
                
            elif state == "choosing_category":
                if self._is_valid_category_choice(normalized_message, self.current_context):
                    self.current_context["state"] = "choosing_model"
                    category = self.current_context.get("category")
                    self.current_context["available_models"] = self._get_available_models(category)
                    return self._show_available_models(category)
                else:
                    return "Veuillez choisir une cat√©gorie valide.\n\n" + self._show_available_categories()
                
            elif state == "choosing_model":
                if self._is_valid_model_choice(normalized_message, self.current_context):
                    self.current_context["state"] = "asking_client"
                    if normalized_message.isdigit():
                        index = int(normalized_message) - 1
                        available_models = self.current_context.get("available_models", [])
                        if 0 <= index < len(available_models):
                            self.current_context["model"] = available_models[index]
                    else:
                        self.current_context["model"] = normalized_message
                    
                    return """Pour quel client souhaitez-vous utiliser ce mod√®le ?
Veuillez entrer le nom du client ou son identifiant."""
                else:
                    category = self.current_context.get("category")
                    return "Veuillez choisir un mod√®le valide.\n\n" + self._show_available_models(category)
                
            elif state == "asking_client":
                # Chercher le client dans la base de donn√©es
                client_name = message.strip()
                clients = self._search_clients(client_name)
                
                if not clients:
                    self.current_context["client"] = client_name
                    self.current_context["state"] = "client_not_found"
                    return f"""‚ö†Ô∏è Je n'ai pas trouv√© de client correspondant √† "{client_name}".

Souhaitez-vous :
1Ô∏è‚É£ Cr√©er un nouveau client
2Ô∏è‚É£ R√©essayer avec un autre nom
3Ô∏è‚É£ Continuer sans client"""
                
                elif len(clients) == 1:
                    # Un seul client trouv√©, on le s√©lectionne
                    self.current_context["client"] = clients[0]
                    self.current_context["state"] = "model_selected"
                    
                    # D√©terminer si les informations sont disponibles
                    entreprise = clients[0].get('entreprise', '')
                    email = clients[0].get('email', '')
                    telephone = clients[0].get('t√©l√©phone', '')
                    
                    return f"""‚úÖ Client trouv√© : {clients[0]['nom']}
                    
üìã D√©tails du client :
üè¢ Entreprise : {entreprise if entreprise else 'Non disponible'}
üìß Email : {email if email else 'Non disponible'}
üìû T√©l√©phone : {telephone if telephone else 'Non disponible'}

Que souhaitez-vous faire avec ce mod√®le ?
1Ô∏è‚É£ Remplir le document
2Ô∏è‚É£ Utiliser tel quel"""
                
                else:
                    # Plusieurs clients trouv√©s, demander √† l'utilisateur de choisir
                    self.current_context["state"] = "choosing_client"
                    self.current_context["available_clients"] = clients
                    
                    # Cr√©er une liste format√©e des clients avec les informations disponibles
                    clients_list = []
                    for i, client in enumerate(clients):
                        # R√©cup√©rer les informations disponibles
                        nom = client.get('nom', 'Sans nom')
                        entreprise = client.get('entreprise', '')
                        email = client.get('email', '')
                        
                        # Cr√©er la ligne avec les informations disponibles
                        client_line = f"{i+1}Ô∏è‚É£ {nom}"
                        if entreprise:
                            client_line += f" - {entreprise}"
                        if email:
                            client_line += f" - {email}"
                            
                        clients_list.append(client_line)
                    
                    formatted_clients = "\n".join(clients_list)
                    return f"""J'ai trouv√© plusieurs clients correspondants :

{formatted_clients}

Veuillez choisir un client en tapant son num√©ro."""
                    
            elif state == "choosing_client":
                if normalized_message.isdigit():
                    index = int(normalized_message) - 1
                    available_clients = self.current_context.get("available_clients", [])
                    
                    if 0 <= index < len(available_clients):
                        self.current_context["client"] = available_clients[index]
                        self.current_context["state"] = "model_selected"
                        
                        # D√©terminer si les informations sont disponibles
                        entreprise = available_clients[index].get('entreprise', '')
                        email = available_clients[index].get('email', '')
                        telephone = available_clients[index].get('t√©l√©phone', '')
                        
                        return f"""‚úÖ Client s√©lectionn√© : {available_clients[index]['nom']}

üìã D√©tails du client :
üè¢ Entreprise : {entreprise if entreprise else 'Non disponible'}
üìß Email : {email if email else 'Non disponible'}
üìû T√©l√©phone : {telephone if telephone else 'Non disponible'}

Que souhaitez-vous faire avec ce mod√®le ?
1Ô∏è‚É£ Remplir le document
2Ô∏è‚É£ Utiliser tel quel"""
                    
                return """‚ö†Ô∏è Veuillez choisir un client valide en tapant son num√©ro."""
                    
            elif state == "client_not_found":
                if normalized_message == "1":
                    self.current_context["state"] = "creating_client"
                    return """Pour cr√©er un nouveau client, j'ai besoin des informations suivantes :

1. Nom complet
2. Email
3. T√©l√©phone
4. Adresse

Veuillez me donner ces informations."""
                    
                elif normalized_message == "2":
                    self.current_context["state"] = "asking_client"
                    return "Veuillez entrer un autre nom de client :"
                    
                elif normalized_message == "3":
                    self.current_context["state"] = "model_selected"
                    return """Que souhaitez-vous faire avec ce mod√®le ?
1Ô∏è‚É£ Remplir le document
2Ô∏è‚É£ Utiliser tel quel"""
                    
                else:
                    return """‚ö†Ô∏è Option non valide.

Souhaitez-vous :
1Ô∏è‚É£ Cr√©er un nouveau client
2Ô∏è‚É£ R√©essayer avec un autre nom
3Ô∏è‚É£ Continuer sans client"""
                    
            elif state == "model_selected":
                if normalized_message == "1":
                    self.current_context["state"] = "filling_document"
                    return "D'accord, je vais vous aider √† remplir ce document. Commen√ßons par le nom du client."
                elif normalized_message == "2":
                    model_path = self.get_model_path(self.current_context.get("category"), self.current_context.get("model"))
                    if self._open_document(model_path):
                        return "Le document a √©t√© ouvert. Souhaitez-vous cr√©er un autre document ?"
                    else:
                        return "D√©sol√©, je n'ai pas pu ouvrir le document. Veuillez r√©essayer."
                else:
                    return """Veuillez choisir une option :

1Ô∏è‚É£ Remplir le document
2Ô∏è‚É£ Utiliser tel quel"""
                
            elif state == "creating_new":
                # Stocker les informations fournies
                if "form_info" not in self.current_context:
                    self.current_context["form_info"] = []
                self.current_context["form_info"].append(message)
                
                return """‚úÖ Information enregistr√©e.

Avez-vous d'autres informations √† ajouter ?
Tapez 'terminer' quand vous avez fini."""
                
            else:
                return """Je ne comprends pas votre demande dans ce contexte.

üìå Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document"""
                
        except Exception as e:
            logger.error(f"Erreur dans _process_current_state: {e}")
            return "Une erreur s'est produite. Veuillez r√©essayer."

    def _generate_llama_response(self, message, stream=False):
        """
        G√©n√®re une r√©ponse en utilisant l'API Llama.
        """
        global ollama_consecutive_failures
        try:
            if not should_use_ollama():
                logger.warning("Ollama n'est pas disponible. Utilisation d'une r√©ponse par d√©faut.")
                return "Je suis d√©sol√©, je ne peux pas r√©pondre √† cette question pour le moment. Comment puis-je vous aider avec vos documents ?"

            prompt = f"""Tu es un assistant IA amical et professionnel sp√©cialis√© dans la gestion de documents.
R√©ponds √† la question suivante de fa√ßon directe et concise: {message}"""

            params = {
                "model": self.model,
                "prompt": prompt,
                "stream": stream,
                "temperature": 0.7,
                "max_tokens": 800,
                "top_p": 0.9,
                "stop": ["Question:", "Humain:", "Utilisateur:", "\n\n"]
            }

            response = session.post(
                "http://localhost:11434/api/generate",
                json=params,
                timeout=30
            )

            if response.status_code == 200:
                ollama_consecutive_failures = 0

                if stream:
                    return self._stream_response(response)
                else:
                    result = response.json()
                    if "response" in result:
                        return self._clean_response(result["response"])

            ollama_consecutive_failures += 1
            logger.warning(f"Erreur d'API Ollama ({response.status_code}). √âchecs cons√©cutifs: {ollama_consecutive_failures}")
            return "Je suis d√©sol√©, je rencontre des difficult√©s pour r√©pondre √† cette question. Comment puis-je vous aider avec vos documents ?"

        except Exception as e:
            ollama_consecutive_failures += 1
            logger.error(f"Erreur lors de l'appel √† Llama: {e}")
            logger.error(traceback.format_exc())
            return "Je suis d√©sol√©, une erreur technique m'emp√™che de r√©pondre. Comment puis-je vous aider avec vos documents ?"

    def patched_generate_response(self, message, stream=False):
        """
        Version patch√©e de generate_response avec une meilleure gestion des √©tats
        et des r√©ponses plus naturelles
        """
        try:
            # Ne pas traiter les messages vides
            if not message or len(message.strip()) == 0:
                return "Je n'ai pas compris votre message. Pourriez-vous reformuler?"
            
            # Normaliser l'entr√©e pour la recherche
            if not hasattr(self, '_normalize_input'):
                def _normalize_input(self, text):
                    """Normalise le texte en entr√©e"""
                    if not text:
                        return ""
                    # Convertir en minuscules et supprimer les espaces inutiles
                    text = text.lower().strip()
                    # Supprimer les accents
                    text = ''.join(c for c in unicodedata.normalize('NFD', text)
                                if unicodedata.category(c) != 'Mn')
                    return text
                self._normalize_input = types.MethodType(_normalize_input, self)
            
            normalized_input = self._normalize_input(message)
            
            # DEBUG
            print(f"DEBUG - patched_generate_response - Message re√ßu: '{message}'")
            print(f"DEBUG - patched_generate_response - Message normalis√©: '{normalized_input}'")
            print(f"DEBUG - patched_generate_response - √âtat actuel: '{self.current_context.get('state', 'initial')}'")
            
            # G√©rer directement les choix 1 et 2 dans l'√©tat asking_document_type
            current_state = self.current_context.get('state', 'initial')
            
            # Gestion sp√©ciale pour les choix 1 et 2 dans tous les √©tats pertinents
            if normalized_input == "1" or normalized_input == "2":
                # Si dans l'√©tat initial ou asking_document_type
                if current_state in ["initial", "asking_document_type"]:
                    if normalized_input == "1":
                        # Option 1: Utiliser un mod√®le existant
                        self.current_context["state"] = "choosing_category"
                        self.current_context["last_action"] = "choisir_modele_existant"
                        # Assurer que le chemin des mod√®les est d√©fini
                        if not hasattr(self, 'models_path'):
                            self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
                        # Mettre √† jour les cat√©gories disponibles
                        self.current_context["available_categories"] = self._get_available_categories()
                        return self._show_available_categories()
                    else:  # normalized_input == "2"
                        # Option 2: Cr√©er un nouveau document
                        self.current_context["state"] = "creating_new"
                        self.current_context["last_action"] = "creer_nouveau_document"
                        return """Pour cr√©er un nouveau document, j'ai besoin de quelques informations :

1. Quel type de document souhaitez-vous cr√©er ?
2. Quel est son objectif ?
3. Quelles informations doit-il contenir ?

Veuillez me donner ces informations."""
            
            # D√©tection sp√©cifique pour "cv" et "cava" qui peuvent √™tre ambigus
            if normalized_input in ["cv", "cava", "ca va", "√ßa va"]:
                print(f"DEBUG - D√©tection sp√©ciale pour '{normalized_input}'")
                return """Je vais tr√®s bien, merci ! üëã

Je peux vous aider √† :
üìÑ Cr√©er un nouveau document
üìù Utiliser un mod√®le existant
üß© Remplir des mod√®les avec vos informations

Que souhaitez-vous faire ?"""
            
            # Si nous sommes dans un √©tat sp√©cifique du workflow, traiter avec _handle_workflow
            if current_state != "initial":
                print(f"DEBUG - √âtat non initial: '{current_state}', utilisation de _handle_workflow")
                # Priorit√© √† _handle_workflow pour les √©tats sp√©cifiques
                workflow_response = self._handle_workflow(message)
                if workflow_response:
                    return workflow_response
                
                # Si _handle_workflow ne donne pas de r√©ponse, essayer _handle_model_actions
                model_action_response = self._handle_model_actions(message)
                if model_action_response:
                    return model_action_response

                # Si on est toujours dans asking_document_type et les chiffres 1/2 sont entr√©s
                if current_state == "asking_document_type" and normalized_input in ["1", "2"]:
                    print(f"DEBUG - R√©ponse forc√©e pour '{normalized_input}' dans l'√©tat '{current_state}'")
                    if normalized_input == "1":
                        self.current_context["state"] = "choosing_category"
                        self.current_context["last_action"] = "choisir_modele_existant"
                        return self._show_available_categories()
                    else:  # normalized_input == "2"
                        self.current_context["state"] = "creating_new"
                        self.current_context["last_action"] = "creer_nouveau_document"
                        return """Pour cr√©er un nouveau document, j'ai besoin de quelques informations :

1. Quel type de document souhaitez-vous cr√©er ?
2. Quel est son objectif ?
3. Quelles informations doit-il contenir ?

Veuillez me donner ces informations."""
            
            # Patterns renforc√©s pour les salutations
            greeting_patterns = [
                # Salutations simples
                r'\b(?:salut|bonjour|bonsoir|hey|hi|hello|coucou|yo|hola)\b',
                # Variations de "√ßa va"
                r'\b(?:ca|√ßa)\s*(?:va|vas?)\b',
                r'\bcomment\s*(?:ca|√ßa)\s*(?:va|vas?)\b',
                r'\bcomment\s*(?:tu\s*)?(?:vas?|allez)\b',
                r'\btu\s*vas?\s*bien\b',
                # Variations de "cv"
                r'\bcv\b',
                r'\bc+\s*v+\b',
                r'\bsv+[tp]?\b',
                # Formules de politesse
                r'\benchant√©\b',
                r'\bravi\b',
                r'\bplaisir\b',
                # Moments de la journ√©e
                r'\bbonne?\s*(?:journ√©e|soir√©e|nuit|matin√©e|apr√®s[\s-]midi)\b'
            ]
            
            # Si c'est une salutation
            if any(re.search(pattern, normalized_input, re.IGNORECASE) for pattern in greeting_patterns):
                print(f"DEBUG - C'est une salutation: '{normalized_input}'")
                return """Je vais tr√®s bien, merci ! üëã

Je peux vous aider √† :
üìÑ Cr√©er un nouveau document
üìù Utiliser un mod√®le existant
üß© Remplir des mod√®les avec vos informations

Que souhaitez-vous faire ?"""
            
            # Patterns renforc√©s pour les commandes courtes
            short_command_patterns = {
                # Commandes d'accord
                "accord": [r'\b(?:ok|okay|ok√©|oki|oui|ouais?|yep|yes|yeah|dac+(?:ord)?|bien|tr√®s?\s*bien|parfait|super|excellent|g√©nial|cool|nickel|top)\b'],
                # Commandes de refus
                "refus": [r'\b(?:non|no|nope|pas|jamais)\b'],
                # Commandes de continuation
                "continue": [r'\b(?:suivant|continue[rz]?|apr√®s|ensuite|puis|next)\b'],
                # Commandes de retour
                "retour": [r'\b(?:retour|back|pr√©c√©dent|precedent|arri√®re|revenir|annuler|cancel)\b'],
                # Commandes de fin
                "fin": [r'\b(?:fin|fini|terminer?|stop|arr√™te[rz]?|quitter?|exit|bye|au\s*revoir|a\+)\b'],
                # Commandes de r√©p√©tition
                "repeter": [r'\b(?:r√©p√©te[rz]?|repeat|redis|encore|again)\b'],
                # Commandes d'aide
                "aide": [r'\b(?:aide|help|sos|besoin|aider?)\b']
            }
            
            # V√©rifier les commandes courtes
            for command_type, patterns in short_command_patterns.items():
                if any(re.search(pattern, normalized_input, re.IGNORECASE) for pattern in patterns):
                    print(f"DEBUG - C'est une commande courte de type '{command_type}': '{normalized_input}'")
                    # Si nous sommes dans l'√©tat initial
                    if self.current_context["state"] == "initial":
                        if command_type == "accord":
                            return self._show_available_categories()
                        elif command_type in ["fin", "retour"]:
                            return """Au revoir ! N'h√©sitez pas √† revenir si vous avez besoin d'aide pour vos documents. üëã"""
                    # Si nous venons de terminer un document
                    elif self.current_context.get("last_action") == "document_completed":
                        if command_type == "accord":
                            return """Excellent ! Je suis ravi d'avoir pu vous aider. 

Souhaitez-vous cr√©er un autre document ?
1Ô∏è‚É£ Oui, cr√©er un autre document
2Ô∏è‚É£ Non, c'est tout pour aujourd'hui"""
                    
                    # Pour toute autre commande d'accord dans un autre √©tat
                    if command_type == "accord":
                        result = self._handle_model_actions(message)
                        print(f"DEBUG - R√©sultat de _handle_model_actions pour commande '{command_type}': {result}")
                        return result if result else self._handle_workflow(message)
                    elif command_type == "aide":
                        return """Je suis l√† pour vous aider ! Voici ce que je peux faire :

1Ô∏è‚É£ Utiliser un mod√®le existant de document
2Ô∏è‚É£ Cr√©er un nouveau document personnalis√©
3Ô∏è‚É£ Remplir automatiquement vos documents

Que souhaitez-vous faire ?"""
                    
            # Patterns renforc√©s pour les demandes de documents
            doc_patterns = [
                # Types de documents
                r'\b(?:document|doc|fichier|dossier|papier)s?\b',
                r'\b(?:modele|mod√®le|template|exemple|formulaire)s?\b',
                r'\b(?:contrat|facture|devis|lettre|attestation|certificat|d√©claration)s?\b',
                r'\b(?:image|photo|figure|graphique|diagramme|sch√©ma)s?\b',
                r'\b(?:pdf|word|excel|powerpoint|ppt|docx|xlsx|txt)s?\b',
                
                # Actions sur les documents
                r'\b(?:cr√©er|creer|faire|g√©n√©rer|generer|r√©diger|rediger|√©crire|ecrire)\b',
                r'\b(?:remplir|completer|compl√©ter|modifier|√©diter|editer)\b',
                r'\b(?:utiliser|ouvrir|voir|afficher|montrer|consulter)\b',
                
                # Expressions de besoin
                r'\b(?:je\s*(?:veux|voudrais|souhaite|aimerais|dois|peux|dois|cherche))\b',
                r'\b(?:il\s*(?:me\s*)?faut)\b',
                r'\b(?:j\'ai\s*besoin)\b',
                r'\b(?:besoin\s*d[e\'])\b',
                
                # Cat√©gories sp√©cifiques
                r'\b(?:administratif|juridique|commercial|financier|technique)\b',
                r'\b(?:personnel|professionnel|officiel|standard|template)\b',
                
                # Variations et fautes courantes
                r'\b(?:documant|documment|documens|documant)s?\b',
                r'\b(?:je\s*(?:veut|veu|veus|veus|vx))\b',
                r'\bunn?\s*(?:document|doc)s?\b',
                r'\b(?:cre+|cr√©+)(?:er?|√©)\b',
                r'\b(?:model|modl|modle|modele)s?\b',
                
                # Expressions informelles
                r'\b(?:truc|chose|papier|feuille)s?\b',
                r'\bfaut\s*(?:que|qu\')\s*(?:je|j\')\b',
                
                # Demandes indirectes
                r'\b(?:comment|o√π|ou)\s*(?:je|j\'|on)\s*(?:peux?|dois|fait|trouve)\b',
                r'\b(?:aide|help|sos|besoin\s*d\'aide)\b',
                
                # Symboles et emojis courants
                r'[üìÑüìù‚úçÔ∏èüìãüìé]',
                
                # Expressions de d√©but
                r'^(?:ok|okay|dac|bien|super|parfait|go|allez|aller)\b'
            ]
            
            # Si c'est une demande de document ou si nous sommes d√©j√† dans le processus
            if any(re.search(pattern, normalized_input, re.IGNORECASE) for pattern in doc_patterns) or current_state != "initial":
                # Si l'utilisateur a entr√© 1 ou 2
                if normalized_input in ["1", "2"]:
                    if normalized_input == "1":
                        self.current_context["state"] = "choosing_category"
                        self.current_context["last_action"] = "choisir_modele_existant"
                        return self._show_available_categories()
                    else:  # normalized_input == "2"
                        self.current_context["state"] = "creating_new"
                        self.current_context["last_action"] = "creer_nouveau_document"
                        return """Pour cr√©er un nouveau document, j'ai besoin de quelques informations :

1. Quel type de document souhaitez-vous cr√©er ?
2. Quel est son objectif ?
3. Quelles informations doit-il contenir ?

Veuillez me donner ces informations."""
                
                # Si c'est une salutation simple
                if normalized_input in ["cv", "cava", "ca va", "√ßa va"]:
                    return """Je vais tr√®s bien, merci ! üëã

Je peux vous aider √† :
üìÑ Cr√©er un nouveau document
üìù Utiliser un mod√®le existant
üß© Remplir des mod√®les avec vos informations

Que souhaitez-vous faire ?"""
                
                # R√©ponse par d√©faut pour une demande de document
                return """üìå Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document"""
            
            # Si nous sommes dans un √©tat sp√©cifique du workflow, ne pas utiliser Llama
            if self.current_context["state"] != "initial":
                workflow_response = self._handle_workflow(message)
                if workflow_response:
                    return workflow_response
                
                return self._handle_model_actions(message)
            
            # Si c'est un chiffre ou un num√©ro seul
            if re.match(r'^\d+$', normalized_input):
                return self._handle_model_actions(message)
            
            # Patterns renforc√©s pour les questions
            question_patterns = [
                # Mots interrogatifs
                r'\b(?:comment|pourquoi|quand|o√π|qui|quel(?:le)?s?|quoi|combien|lequel)\b',
                r'\b(?:qu[\'e](?:st[-\s]ce\s*(?:que)?)?)\b',
                # Inversions interrogatives
                r'\b(?:peux[-\s]tu|pouvez[-\s]vous|sais[-\s]tu|savez[-\s]vous)\b',
                r'\b(?:est[-\s]ce\s*(?:que)?|as[-\s]tu|avez[-\s]vous)\b',
                # Marqueurs de question
                r'\?+',
                # Expressions de demande d'information
                r'\b(?:explique[rz]?[-\s]moi|dis[-\s]moi|montre[-\s]moi)\b',
                r'\b(?:je\s*(?:veux|voudrais|souhaite|aimerais)\s*savoir)\b'
            ]
            
            # Si c'est une question
            is_question = (
                any(re.search(pattern, normalized_input, re.IGNORECASE) for pattern in question_patterns) or
                len(message.split()) > 3  # Si c'est une phrase plus longue
            )
            
            if is_question:
                return self._generate_llama_response(message, stream)
            else:
                # Pour tout autre cas, montrer le menu principal
                self._reset_context()
                return """Je peux vous aider √† g√©rer vos documents. Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document"""
                
        except Exception as e:
            logger.error(f"Erreur dans patched_generate_response: {e}")
            logger.error(traceback.format_exc())
            print(f"DEBUG - Exception dans patched_generate_response: {e}")
            return "Une erreur s'est produite lors du traitement de votre demande. Veuillez r√©essayer ou contacter l'assistance."

    def patched_handle_user_choice(self, user_input):
        """
        Version am√©lior√©e de _handle_user_choice qui g√®re mieux les entr√©es de l'utilisateur
        et les changements de contexte.
        """
        try:
            msg_lower = user_input.lower().strip()
            
            # V√©rifier les salutations
            greeting_patterns = [
                r'\bcava\b', r'\b√ßa va\b', r'\bcomment √ßa va\b', r'\bcomment vas[\s-]tu\b', 
                r'\bcomment tu vas\b', r'\bcomment tu va\b', r'\btu vas bien\b',
                r'\bcomment cv\b', r'\bcv\??\b', r'\bbonjour\b', r'\bsalut\b', r'\bhello\b'
            ]
            
            # Si c'est une simple salutation
            if any(re.search(pattern, msg_lower) for pattern in greeting_patterns) and len(user_input.split()) <= 3:
                current_state = self.current_context.get("state", "initial")
                
                # Si nous sommes au d√©but
                if current_state in ["initial", "greeting"]:
                    self.current_context["state"] = "greeting"
                    return "Je vais tr√®s bien, merci ! Comment puis-je vous aider avec vos documents aujourd'hui ?"
                
                # Si nous sommes au milieu d'un processus
                if current_state == "choosing_category":
                    return "Je vais bien, merci ! Pour continuer, veuillez choisir une cat√©gorie de document parmi celles propos√©es."
                elif current_state == "choosing_model":
                    return "Je vais bien, merci ! Pour continuer, veuillez choisir un mod√®le de document parmi ceux propos√©s."
                elif current_state == "model_selected":
                    return "Je vais bien, merci ! Pour continuer, que souhaitez-vous faire avec le document s√©lectionn√© ?"
                else:
                    return "Je vais bien, merci ! Continuons avec votre document. Comment puis-je vous aider ?"
            
            # V√©rifier si c'est une demande d'avis sur un document
            opinion_doc_patterns = [
                r'ton avis sur ce(tte)? doc(ument)?', r'penses[\s-]tu (de )?ce doc(ument)?',
                r'avis sur (le|ce) (document|mod√®le|fichier|template)',
                r'que penses[\s-]tu (de )?ce(tte)? (document|mod√®le|fichier|template)'
            ]
            
            is_opinion_doc_request = any(re.search(pattern, msg_lower) for pattern in opinion_doc_patterns)
            
            # Si l'utilisateur demande un avis sur un document sp√©cifique
            current_state = self.current_context.get("state", "initial")
            if is_opinion_doc_request and current_state in ["choosing_model", "model_selected"]:
                # Extraire le document actuellement s√©lectionn√© s'il existe
                current_model = self.current_context.get("model")
                current_category = self.current_context.get("category")
                
                if current_model and current_category:
                    # V√©rifier si Ollama est disponible et fiable
                    if should_use_ollama():
                        try:
                            # Cr√©er un prompt adapt√© pour l'avis sur le document
                            prompt = f"""Je suis un assistant IA qui aide √† cr√©er des documents. L'utilisateur me demande mon avis sur un document de type '{current_category}', nomm√© '{current_model}'. 
Comment puis-je lui donner un avis professionnel et utile sur ce document sans l'avoir vu, en me basant sur son type et son nom?"""
                            
                            # G√©n√©rer une r√©ponse avec Llama
                            llama_response = self._get_llama_response(prompt)
                            
                            # Si Llama a r√©ussi √† g√©n√©rer une r√©ponse pertinente
                            if llama_response and len(llama_response) > 15:
                                context_reminder = "\n\nSi vous souhaitez utiliser ce document, vous pouvez :\n1Ô∏è‚É£ Le remplir maintenant\n2Ô∏è‚É£ L'utiliser tel quel\n\nVeuillez choisir en tapant 1 ou 2."
                                full_response = llama_response + context_reminder
                                
                                # Mettre √† jour l'√©tat
                                self.current_context["state"] = "model_selected"
                                
                                return full_response
                        except Exception as e:
                            logger.error(f"Erreur lors de la g√©n√©ration d'avis sur document: {e}")
                            logger.error(traceback.format_exc())
                    
                    # Si Ollama n'est pas disponible ou a √©chou√©, utiliser une r√©ponse par d√©faut
                    return f"Ce document '{current_model}' de la cat√©gorie '{current_category}' semble √™tre un bon choix pour votre besoin. Souhaitez-vous:\n1Ô∏è‚É£ Le remplir maintenant\n2Ô∏è‚É£ L'utiliser tel quel\n\nVeuillez choisir en tapant 1 ou 2."
                else:
                    # Si aucun document n'est encore s√©lectionn√©
                    return "Veuillez d'abord s√©lectionner un document sp√©cifique pour que je puisse vous donner mon avis dessus."
            
            # V√©rifier si c'est une demande courte de document
            doc_request_patterns = [
                # Demandes directes de document
                r'\b(?:je\s*(?:veux|voudrais|souhaite|aimerais)\s*(?:un|une|des|le|la|les)?\s*(?:docs?|documents?|modele?s?|mod√®le?s?))\b',
                r'\bun\s*(?:docs?|documents?|modele?s?|mod√®le?s?)\b',
                r'\b(?:creer|cr√©er|faire|nouveau)\s*(?:un|une|des|le|la|les)?\s*(?:docs?|documents?|modele?s?|mod√®le?s?)\b',
                r'\b(?:utiliser|prendre|choisir|voir)\s*(?:un|une|des|le|la|les)?\s*(?:docs?|documents?|modele?s?|mod√®le?s?)\s*(?:existants?|disponibles?)?\b',
                
                # Mots-cl√©s simples
                r'\b(?:docs?|documents?|modele?s?|mod√®le?s?)\b',
                r'\b(?:existants?|nouveaux?|disponibles?)\b',
                r'\b(?:creer|cr√©er|faire|nouveau)\b',
                
                # Variations et fautes courantes
                r'\b(?:documant|documment|documens|documan)s?\b',
                r'\b(?:modl|modle|modele|model)s?\b',
                r'\b(?:cre+|cr√©+)(?:er?|√©)\b',
                
                # Expressions de besoin
                r'\b(?:il\s*(?:me\s*)?faut)\b',
                r'\b(?:j\'ai\s*besoin)\b',
                r'\b(?:besoin\s*d[e\'])\b'
            ]
            
            # Normaliser l'entr√©e utilisateur
            normalized_input = message.lower().strip()
            
            # Si c'est une demande de document (v√©rifier tous les patterns)
            if any(re.search(pattern, normalized_input, re.IGNORECASE) for pattern in doc_request_patterns):
                # Si nous sommes d√©j√† dans un √©tat sp√©cifique, continuer le processus
                if current_state != "initial":
                    return {
                        "response": self._get_state_response(current_state),
                        "state": current_state,
                        "action": "continue_process"
                    }
                
                # Sinon, commencer le processus
                return {
                    "response": """üìå Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document

Veuillez choisir une option en tapant 1 ou 2.""",
                    "state": "asking_document_type",
                    "action": "demande_document"
                }
            
            # D√©tecter s'il s'agit d'une question g√©n√©rale ou d'une demande d'information
            general_question_patterns = [
                r'\bpourquoi\b', r'\bcomment\b', r'\bquand\b', r'\bo√π\b', r'\bqui\b', 
                r'\bquel\b', r'\bquelle\b', r'\bcombien\b', r'\bque\b', r'\bqu\'est(-ce)?(\s+que)?\b'
            ]
            
            # Patterns pour les demandes d'avis
            opinion_patterns = [
                r'\bpenses[\s-]tu\b', r'\bton avis\b', r'\bpenses[\s-]tu\b', 
                r'\bton opinion\b', r'\bque penses[\s-]tu\b'
            ]
            
            is_general_question = any(re.search(pattern, msg_lower) for pattern in general_question_patterns)
            is_opinion_request = any(re.search(pattern, msg_lower) for pattern in opinion_patterns)
            
            # Si c'est une question g√©n√©rale ou une demande d'avis pendant le processus
            if (is_opinion_request or (is_general_question and len(user_input.split()) > 3)) and current_state not in ["initial", "greeting"]:
                # Utiliser Llama pour r√©pondre tout en maintenant le contexte
                try:
                    # V√©rifier si Ollama est disponible
                    if not should_use_ollama():
                        logger.warning("Ollama n'est pas disponible dans _handle_user_choice. Utilisation du comportement standard.")
                        return original_handle_user_choice(self, user_input)
                        
                    # Adapter le prompt en fonction du type de question
                    if is_opinion_request:
                        prompt = f"L'utilisateur me demande mon avis pendant le processus de document: {user_input}. R√©ponds de fa√ßon sympathique et professionnelle."
                    else:
                        prompt = f"L'utilisateur me pose cette question pendant le processus de document: {user_input}. R√©ponds de fa√ßon concise et pr√©cise."
                    
                    # G√©n√©rer une r√©ponse avec Llama
                    llama_response = self._get_llama_response(prompt)
                    
                    # V√©rifier que la r√©ponse est valide
                    if llama_response and len(llama_response) > 15:
                        # D√©terminer un rappel du contexte bas√© sur l'√©tat actuel
                        if current_state == "choosing_category":
                            context_reminder = "\n\nPour revenir √† notre processus, veuillez choisir une cat√©gorie de document."
                        elif current_state == "choosing_model":
                            context_reminder = "\n\nPour revenir √† notre processus, veuillez choisir un mod√®le de document."
                        elif current_state == "model_selected":
                            context_reminder = "\n\nPour revenir √† notre processus, veuillez indiquer ce que vous souhaitez faire avec le document."
                        else:
                            context_reminder = "\n\nMaintenant, revenons √† votre document."
                        
                        return llama_response + context_reminder
                except Exception as e:
                    logger.error(f"Erreur lors de l'appel √† Llama dans _handle_user_choice: {e}")
                    # En cas d'erreur, continuer avec le comportement normal
            
            # Pour toute autre entr√©e utilisateur pendant le processus, essayer d'utiliser Llama
            if current_state not in ["initial", "greeting"] and len(user_input.split()) > 1:
                try:
                    # V√©rifier si Ollama est disponible
                    if not should_use_ollama():
                        logger.warning("Ollama n'est pas disponible pour le traitement g√©n√©ral dans _handle_user_choice. Utilisation du comportement standard.")
                        return original_handle_user_choice(self, user_input)
                        
                    # Cr√©er un prompt contextualis√©
                    prompt = f"Je suis un assistant IA qui aide √† cr√©er des documents. L'utilisateur est en train de {self._get_state_description(current_state)} et me dit: '{user_input}'. Comment dois-je interpr√©ter cette entr√©e et y r√©pondre de mani√®re utile?"
                    
                    # G√©n√©rer une r√©ponse avec Llama
                    llama_response = self._get_llama_response(prompt)
                    
                    # Si Llama a r√©ussi √† g√©n√©rer une r√©ponse pertinente
                    if llama_response and len(llama_response) > 15:
                        # Ajouter un rappel contextuel
                        if current_state == "choosing_category":
                            context_reminder = "\n\nVeuillez choisir une cat√©gorie de document pour continuer."
                        elif current_state == "choosing_model":
                            context_reminder = "\n\nVeuillez choisir un mod√®le de document pour continuer."
                        elif current_state == "model_selected":
                            context_reminder = "\n\nVeuillez indiquer ce que vous souhaitez faire avec le document."
                        else:
                            context_reminder = "\n\nContinuons avec votre document."
                        
                        return llama_response + context_reminder
                except Exception as e:
                    logger.error(f"Erreur lors de l'appel g√©n√©ral √† Llama dans _handle_user_choice: {e}")
                    # En cas d'erreur, continuer avec le comportement normal
            
            # Appliquer le comportement normal pour tous les autres cas
            return original_handle_user_choice(self, user_input)
            
        except Exception as e:
            # Capturer les erreurs et fournir une r√©ponse utile
            logger.error(f"Erreur dans _handle_user_choice: {e}")
            logger.error(traceback.format_exc())
            
            # R√©initialiser le contexte et reprendre depuis le d√©but
            self.current_context["state"] = "asking_document_type"
            return """Je suis d√©sol√©, j'ai perdu le contexte de notre conversation. Reprenons :

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document

Veuillez choisir une option en tapant 1 ou 2."""

    def _analyze_document_with_llama(self, document_text):
        """
        Utilise Llama pour analyser le document et d√©tecter les variables personnalisables.
        """
        try:
            prompt = f"""Tu es un assistant sp√©cialis√© en analyse et personnalisation de documents.
    
1Ô∏è‚É£ **Analyse le document** et **d√©tecte toutes les variables personnalisables** (Nom, Adresse, Date, Montant, Lieu, etc.).
2Ô∏è‚É£ **√âvite les r√©p√©titions** : Si une variable est pr√©sente plusieurs fois, ne la demande qu'une seule fois.
3Ô∏è‚É£ **G√©n√®re une liste claire des informations n√©cessaires** √† l'utilisateur.

üìÑ **Document :**
```text
{document_text}
```

üîç **R√©sultat attendu (format JSON) :**
```json
{{
    "nom": "??",
    "adresse": "??",
    "date": "??",
    "montant": "??",
    "lieu": "??",
    "t√©l√©phone": "??",
    "r√©f√©rence": "??"
}}
```

Renvoie uniquement la liste des variables trouv√©es sous format JSON. Si une variable n'est pas trouv√©e, ne l'inclus pas."""

            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.model if hasattr(self, 'model') else "llama3",
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.2,
                    "max_tokens": 300
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json().get("response", "{}")
                # Extraire uniquement la partie JSON de la r√©ponse
                json_str = re.search(r'\{.*\}', result, re.DOTALL)
                if json_str:
                    return json.loads(json_str.group())
            return {}

        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du document avec Llama: {e}")
            return {}

    def _refine_document_with_llama(self, final_document):
        """
        Utilise Llama pour am√©liorer la fluidit√© du texte final.
        """
        try:
            prompt = f"""Ce document a √©t√© personnalis√© avec des valeurs fournies par l'utilisateur. 
V√©rifie la fluidit√© du texte et reformule si n√©cessaire.

üìÑ **Document personnalis√© :**
```text
{final_document}
```

üîç **Instructions :**
- Corrige les erreurs grammaticales et syntaxiques
- Reformule pour plus de clart√© et fluidit√©
- Garde le m√™me format et la m√™me structure
- Ne modifie pas les informations personnelles

üì¢ **Texte final corrig√© :**"""

            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.model if hasattr(self, 'model') else "llama3",
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.3,
                    "max_tokens": 500
                },
                timeout=30
            )

            if response.status_code == 200:
                return response.json().get("response", final_document)
            return final_document

        except Exception as e:
            logger.error(f"Erreur lors du raffinement du document avec Llama: {e}")
            return final_document

    def patched_handle_model_actions(self, message: str) -> Dict[str, Any]:
        try:
            # Patterns de demande de document
            doc_request_patterns = [
                # ... existing code ...
            ]
            
            # Normaliser l'entr√©e utilisateur
            normalized_input = message.lower().strip()
            
            # Variables du contexte actuelles
            current_state = self.current_context.get("state", "")
            category = self.current_context.get("category")
            selected_model = self.current_context.get("model")
            last_action = self.current_context.get("last_action", "")
            
            # Liste des commandes de compl√©tion
            completion_commands = [
                "completer", "compl√©ter", "terminer", "fini", "finir", "done",
                "c'est tout", "ca suffit", "√ßa suffit", "ok", "termine"
            ]
            
            # Si nous sommes en train de remplir le document
            if current_state == "filling_document":
                # Si c'est la premi√®re fois (pas encore de client)
                if not self.current_context.get("client_asked"):
                    self.current_context["client_asked"] = True
                    return """Pour commencer, j'ai besoin du nom du client.
Quel est le nom du client pour ce document ?"""
                
                # Si nous attendons le nom du client
                elif not self.current_context.get("client_data"):
                    # Rechercher le client
                    clients = self._search_clients(message)
                    
                    if clients and len(clients) > 0:
                        self.current_context["client_data"] = clients[0]
                        
                        # Analyser le document pour les variables
                        try:
                            model_path = self.get_model_path(category, selected_model)
                            with open(model_path, 'r', encoding='utf-8') as f:
                                document_text = f.read()
                            
                            # Analyser le document avec Llama
                            variables = self._analyze_document_with_llama(document_text)
                            
                            # Compl√©ter avec les donn√©es client
                            completed_vars = self._complete_variables_with_client(variables, clients[0])
                            
                            # Identifier les variables manquantes
                            missing_vars = [var for var, val in completed_vars.items() if val == "??"]
                            
                            if missing_vars:
                                # Il manque des informations √† demander
                                self.current_context["state"] = "filling_missing_vars"
                                self.current_context["missing_vars"] = missing_vars
                                self.current_context["current_vars"] = completed_vars
                                
                                return f"""‚úÖ Client trouv√© : {clients[0]['nom']} ({clients[0]['entreprise']})

J'ai analys√© le document et j'ai besoin des informations suivantes :

{chr(10).join([f"‚Ä¢ {var}" for var in missing_vars])}

Veuillez me donner ces informations une par une."""
                            else:
                                # Toutes les variables sont remplies
                                final_document = document_text
                                for var_name, value in completed_vars.items():
                                    final_document = final_document.replace(f"<<{var_name}>>", value)
                                
                                # Raffiner le document
                                refined_document = self._refine_document_with_llama(final_document)
                                
                                # Sauvegarder le document final
                                output_path = os.path.join(self.models_path, category, f"filled_{selected_model}")
                                with open(output_path, 'w', encoding='utf-8') as f:
                                    f.write(refined_document)
                                
                                return f"""‚úÖ Parfait ! J'ai compl√©t√© le document "{selected_model}" avec les informations du client.

Le document a √©t√© enregistr√© sous : {output_path}

Souhaitez-vous :
1Ô∏è‚É£ Cr√©er un autre document
2Ô∏è‚É£ Terminer et revenir au menu principal"""
                        
                        except Exception as e:
                            logger.error(f"Erreur lors de l'analyse du document: {e}")
                            return """‚ùå Une erreur s'est produite lors de l'analyse du document.

Veuillez r√©essayer ou contacter l'assistance."""
                    
                    else:
                        return """‚ùå Je ne trouve pas ce client dans la base de donn√©es.

Veuillez v√©rifier le nom et r√©essayer, ou tapez 'nouveau' pour cr√©er un nouveau client."""
                
                # V√©rifier si c'est une commande de compl√©tion
                elif normalized_input in completion_commands:
                    # Le reste du code pour la compl√©tion...
                    return self._handle_completion(message)
                
                else:
                    # Ajouter l'information au formulaire
                    if "form_info" not in self.current_context:
                        self.current_context["form_info"] = []
                    self.current_context["form_info"].append(message)
                    return """‚úÖ Information bien enregistr√©e.

Donnez-moi une autre information √† inclure dans le document,
ou tapez 'compl√©ter' quand vous avez termin√©."""
            
            # Si nous sommes en train de remplir les variables manquantes
            elif current_state == "filling_missing_vars":
                missing_vars = self.current_context.get("missing_vars", [])
                current_vars = self.current_context.get("current_vars", {})
                
                if not missing_vars:
                    # Toutes les variables sont remplies, g√©n√©rer le document
                    saved_model = self.current_context.get("completed_model")
                    category = self.current_context.get("category")
                    
                    try:
                        model_path = self.get_model_path(category, saved_model)
                        with open(model_path, 'r', encoding='utf-8') as f:
                            document_text = f.read()
                        
                        # G√©n√©rer le document final
                        final_document = document_text
                        for var_name, value in current_vars.items():
                            final_document = final_document.replace(f"<<{var_name}>>", value)
                        
                        # Raffiner le document avec Llama
                        refined_document = self._refine_document_with_llama(final_document)
                        
                        # Sauvegarder le document final
                        output_path = os.path.join(self.models_path, category, f"filled_{saved_model}")
                        with open(output_path, 'w', encoding='utf-8') as f:
                            f.write(refined_document)
                        
                        # R√©initialiser le contexte
                        self._reset_context()
                        
                        return f"""‚úÖ Parfait ! J'ai compl√©t√© le document "{saved_model}" avec toutes les informations.

Le document a √©t√© enregistr√© sous : {output_path}

Souhaitez-vous :
1Ô∏è‚É£ Cr√©er un autre document
2Ô∏è‚É£ Terminer et revenir au menu principal"""
                        
                    except Exception as e:
                        logger.error(f"Erreur lors de la g√©n√©ration du document final: {e}")
                        return """‚ùå Une erreur s'est produite lors de la g√©n√©ration du document.

Veuillez r√©essayer ou contacter l'assistance."""
                
                # Ajouter la nouvelle information
                current_var = missing_vars[0]
                current_vars[current_var] = message
                missing_vars.pop(0)
                
                self.current_context["missing_vars"] = missing_vars
                self.current_context["current_vars"] = current_vars
                
                if missing_vars:
                    return f"""‚úÖ Information bien enregistr√©e.

Il me manque encore : {missing_vars[0]}"""
                else:
                    return self._handle_model_actions("compl√©ter")
            
            # Le reste du code existant...
            # Remplacer l'appel √† super() par une solution plus simple
            # return super()._handle_model_actions(message)
            return "Je ne comprends pas votre demande dans ce contexte. Veuillez choisir une option parmi celles propos√©es."
            
        except Exception as e:
            logger.error(f"Erreur dans patched_handle_model_actions: {e}")
            logger.error(traceback.format_exc())
            return "Une erreur s'est produite. Veuillez r√©essayer ou contacter l'assistance."

    def _get_state_description(self, state):
        """
        G√©n√®re une description textuelle de l'√©tat actuel pour le prompt Llama.
        """
        descriptions = {
            "choosing_category": "est en train de choisir une cat√©gorie de document parmi une liste propos√©e",
            "choosing_model": "est en train de s√©lectionner un mod√®le de document sp√©cifique dans une cat√©gorie",
            "model_selected": "a s√©lectionn√© un mod√®le de document et doit choisir quoi faire avec (le remplir, le pr√©visualiser, etc.)",
            "filling_document": "est en train de remplir un formulaire pour un document"
        }
        
        try:
            return descriptions.get(state, "est dans une √©tape du processus de gestion de documents")
        except Exception as e:
            logger.error(f"Erreur dans _get_state_description: {e}")
            return "est en train d'utiliser l'application"

    def _open_document(self, path):
        """
        Ouvre un document avec l'application par d√©faut du syst√®me.
        """
        if not os.path.exists(path):
            logger.error(f"Le document n'existe pas: {path}")
            return False
        
        try:
            import platform
            system = platform.system()
            
            if system == 'Windows':
                os.startfile(path)
            elif system == 'Darwin':  # macOS
                import subprocess
                subprocess.call(['open', path])
            else:  # Linux
                import subprocess
                subprocess.call(['xdg-open', path])
            
            logger.info(f"Document ouvert avec succ√®s: {path}")
            return True
        except Exception as e:
            logger.error(f"Erreur lors de l'ouverture du document: {e}")
            return False

    def _get_llama_response(self, message: str) -> str:
        """
        Obtient une r√©ponse pour les interactions de base avec l'utilisateur.
        
        Args:
            message (str): Le message de l'utilisateur
            
        Returns:
            str: La r√©ponse g√©n√©r√©e
        """
        try:
            # V√©rifier si Ollama est disponible
            if not should_use_ollama():
                logger.warning("Ollama n'est pas disponible. Utilisation d'une r√©ponse par d√©faut.")
                return "Je suis d√©sol√©, je ne peux pas r√©pondre √† cette question pour le moment."
                
            # Cr√©er un prompt adapt√©
            prompt = f"L'utilisateur me dit: {message}. Je suis un assistant sp√©cialis√© dans la gestion de documents. Je dois r√©pondre de fa√ßon concise et pr√©cise."
            
            # Appeler l'API Ollama
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.model if hasattr(self, 'model') else "llama3",
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7,
                    "max_tokens": 300
                },
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json().get("response", "Je ne comprends pas votre question.")
            else:
                return "Je suis d√©sol√©, je rencontre des difficult√©s techniques."
                
        except Exception as e:
            logger.error(f"Erreur lors de l'appel √† Llama dans _get_llama_response: {e}")
            return "Je suis d√©sol√©, une erreur technique m'emp√™che de r√©pondre correctement."

    def _show_available_models(self, category):
        """
        Affiche les mod√®les disponibles dans une cat√©gorie en utilisant le mod√®le DocumentTemplate.
        """
        try:
            # V√©rifier si la cat√©gorie est None ou vide
            if not category:
                logger.error("Cat√©gorie non sp√©cifi√©e pour l'affichage des mod√®les")
                return """‚ùå Erreur: Aucune cat√©gorie n'a √©t√© sp√©cifi√©e.

Veuillez d'abord choisir une cat√©gorie valide."""
                
            # V√©rifier si le chemin des mod√®les est d√©fini
            if not hasattr(self, 'models_path'):
                self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
            # Construire le chemin de la cat√©gorie
            category_path = os.path.join(self.models_path, category)
            
            # V√©rifier que le dossier existe
            if not os.path.exists(category_path):
                logger.error(f"La cat√©gorie n'existe pas: {category_path}")
                return f"""‚ùå Je suis d√©sol√©, je ne trouve pas la cat√©gorie "{category}".
                
Veuillez choisir une autre cat√©gorie."""
            
            # Lister les mod√®les (fichiers)
            models = []
            for item in os.listdir(category_path):
                item_path = os.path.join(category_path, item)
                if os.path.isfile(item_path) and not item.startswith('.'):
                    # Obtenir la taille du fichier
                    size = os.path.getsize(item_path)
                    
                    try:
                        # Cr√©er un mod√®le DocumentTemplate valid√©
                        template = DocumentTemplate(
                            name=item,
                            category=category,
                            path=item_path,
                            size=size,
                            variables=[]  # On pourrait les analyser ici si n√©cessaire
                        )
                        models.append(template)
                    except Exception as validation_error:
                        logger.warning(f"Validation du mod√®le {item} √©chou√©e: {validation_error}")
                        # Ignorer ce mod√®le et continuer avec les autres
            
            # Si aucun mod√®le n'est trouv√©
            if not models:
                logger.warning(f"Aucun mod√®le trouv√© dans la cat√©gorie {category}")
                return f"""‚ùå Je ne trouve aucun mod√®le dans la cat√©gorie "{category}".
                
Veuillez choisir une autre cat√©gorie ou contacter l'administrateur syst√®me."""
            
            # Trier les mod√®les par ordre alphab√©tique
            models.sort(key=lambda x: x.name)
            
            # Construire le message de r√©ponse
            response = f"üìÑ Voici les mod√®les disponibles dans la cat√©gorie {category} :\n\n"
            for i, model in enumerate(models, 1):
                # Formater la taille du fichier
                size_str = f"{model.size/1024:.1f} KB" if model.size > 1024 else f"{model.size} bytes"
                
                # Ajouter le mod√®le avec sa taille
                response += f"{i}Ô∏è‚É£ {model.name} ({size_str})\n"
            
            response += "\nVeuillez choisir un mod√®le en tapant son num√©ro ou son nom."
            
            # Mettre √† jour le contexte
            self.current_context["state"] = "choosing_model"
            self.current_context["last_action"] = "afficher_modeles"
            self.current_context["category"] = category
            self.current_context["available_models"] = [model.name for model in models]
            
            return response
                
        except Exception as e:
            logger.error(f"Erreur lors de l'affichage des mod√®les: {e}")
            logger.error(traceback.format_exc())
            return f"""‚ùå Une erreur s'est produite lors de la r√©cup√©ration des mod√®les de la cat√©gorie "{category}".
            
Veuillez r√©essayer ou contacter l'administrateur syst√®me."""

    def _search_client(self, query):
        """
        Recherche des clients dans la base de donn√©es.
        """
        try:
            # Chemin direct vers clients.json, en suivant la configuration
            clients_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'clients', 'clients.json')
            
            # V√©rifier si le fichier existe
            if not os.path.exists(clients_file):
                logger.warning(f"Fichier clients.json non trouv√©: {clients_file}")
                return []
            
            # Charger les clients
            with open(clients_file, 'r', encoding='utf-8') as f:
                clients_data = json.load(f)
            
            # Debug - afficher les clients trouv√©s
            logger.info(f"Recherche de client: '{query}' dans {len(clients_data)} clients")
            
            # Normaliser la recherche
            normalized_query = self._normalize_input(query)
            
            # Rechercher les clients correspondants
            matching_clients = []
            for client in clients_data:
                # V√©rifier que le client est un dict valide avec les champs n√©cessaires
                if not isinstance(client, dict) or 'name' not in client:
                    continue
                    
                # Utiliser les champs name et company pour la recherche
                client_name = self._normalize_input(client.get('name', ''))
                client_company = self._normalize_input(client.get('company', ''))
                client_email = self._normalize_input(client.get('email', ''))
                
                if (normalized_query in client_name or 
                    normalized_query in client_company or 
                    normalized_query in client_email):
                    try:
                        # Cr√©er un mod√®le ClientData valid√©
                        matching_client = ClientData(
                            id=client.get('id', ''),
                            nom=client.get('name', 'Sans nom'),  # Champ obligatoire
                            entreprise=client.get('company', ''),
                            adresse=client.get('address', ''),
                            t√©l√©phone=client.get('phone', ''),
                            email=client.get('email', '')
                        )
                        # Convertir en dictionnaire pour compatibilit√© avec le code existant
                        matching_clients.append(matching_client.dict())
                    except Exception as validation_error:
                        logger.warning(f"Validation du client √©chou√©e: {validation_error}")
                        # Ignorer ce client et continuer avec les autres
            
            # Debug - afficher les correspondances trouv√©es
            logger.info(f"Clients correspondants pour '{query}': {len(matching_clients)}")
            
            return matching_clients
            
        except Exception as e:
            logger.error(f"Erreur lors de la recherche de clients: {e}")
            logger.error(traceback.format_exc())
            return []

    def _complete_variables_with_client(self, variables, client_data):
        """
        Remplit les variables d√©tect√©es avec les donn√©es du client.
        """
        completed_variables = {}
        
        # Mapping des cl√©s du client vers les variables du document
        client_mapping = {
            "nom": ["nom", "client", "nom_client", "client_nom"],
            "entreprise": ["entreprise", "societe", "soci√©t√©", "raison_sociale"],
            "adresse": ["adresse", "adresse_client", "domicile"],
            "t√©l√©phone": ["telephone", "t√©l√©phone", "tel", "t√©l"],
            "email": ["email", "courriel", "mail"]
        }
        
        for var_name, value in variables.items():
            if value == "??":  # Si c'est une variable √† remplir
                # Chercher dans le mapping client
                for client_key, possible_vars in client_mapping.items():
                    if any(possible_var in var_name.lower() for possible_var in possible_vars):
                        if client_key in client_data:
                            completed_variables[var_name] = client_data[client_key]
                            break
                else:
                    # Si la variable n'est pas trouv√©e dans les donn√©es client
                    completed_variables[var_name] = "??"
        
        return completed_variables

    def _get_state_response(self, state):
        """
        Retourne la r√©ponse appropri√©e pour l'√©tat actuel.
        """
        if state == "choosing_category":
            return "Veuillez choisir une cat√©gorie parmi celles propos√©es :\n\n" + self._show_available_categories()
        elif state == "choosing_model":
            category = self.current_context.get("category", "")
            return f"Veuillez choisir un mod√®le dans la cat√©gorie {category} :\n\n" + self._show_available_models(category)
        elif state == "model_selected":
            model = self.current_context.get("model", "")
            return f"""Que souhaitez-vous faire avec le mod√®le "{model}" ?

1Ô∏è‚É£ Remplir le document
2Ô∏è‚É£ Utiliser tel quel"""
        else:
            return """üìå Que souhaitez-vous faire ?

1Ô∏è‚É£ Utiliser un mod√®le existant
2Ô∏è‚É£ Cr√©er un nouveau document

Veuillez choisir une option en tapant 1 ou 2."""

    def _get_available_categories(self):
        """
        Retourne la liste des cat√©gories disponibles.
        """
        try:
            # V√©rifier si le chemin des mod√®les est d√©fini
            if not hasattr(self, 'models_path'):
                self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
            # V√©rifier si le dossier existe
            if not os.path.exists(self.models_path):
                logger.error(f"Dossier des mod√®les non trouv√©: {self.models_path}")
                return []
            
            # Lister les sous-dossiers (cat√©gories)
            categories = [d for d in os.listdir(self.models_path) if os.path.isdir(os.path.join(self.models_path, d))]
            return categories
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des cat√©gories: {e}")
            return []

    def _get_available_models(self, category):
        """
        Retourne la liste des mod√®les disponibles dans une cat√©gorie.
        """
        try:
            # V√©rifier si la cat√©gorie est None ou vide
            if not category:
                logger.error("Cat√©gorie non sp√©cifi√©e pour la r√©cup√©ration des mod√®les")
                return []
                
            # V√©rifier si le chemin des mod√®les est d√©fini
            if not hasattr(self, 'models_path'):
                self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
            # Construire le chemin de la cat√©gorie
            category_path = os.path.join(self.models_path, category)
            
            # V√©rifier que le dossier existe
            if not os.path.exists(category_path):
                logger.error(f"La cat√©gorie n'existe pas: {category_path}")
                return []
            
            # Lister les fichiers (mod√®les)
            models = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f))]
            return models
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des mod√®les: {e}")
            return []

    # Patch the methods
    AIModel._is_simple_thanks = _is_simple_thanks
    AIModel._reset_context = _reset_context
    AIModel._handle_workflow = _handle_workflow
    AIModel._handle_state_transition = _handle_state_transition
    AIModel._process_current_state = _process_current_state
    AIModel._generate_llama_response = _generate_llama_response
    AIModel.generate_response = patched_generate_response
    AIModel._handle_user_choice = patched_handle_user_choice
    AIModel._handle_model_actions = patched_handle_model_actions
    AIModel._get_state_description = _get_state_description
    AIModel._open_document = _open_document
    AIModel._get_llama_response = _get_llama_response
    AIModel._convert_form_info_to_variables = _convert_form_info_to_variables
    AIModel.get_model_path = get_model_path
    AIModel._show_available_categories = _show_available_categories
    AIModel._show_available_models = _show_available_models
    AIModel._is_valid_category_choice = _is_valid_category_choice
    AIModel._is_valid_model_choice = _is_valid_model_choice
    
    
    # Remplacer la m√©thode originale _normalize_input si elle existe
    if hasattr(AIModel, '_normalize_input'):
        original_normalize_input = AIModel._normalize_input
        AIModel._normalize_input = enhanced_normalize_input
    else:
        # Si la m√©thode n'existe pas, l'ajouter directement
        AIModel._normalize_input = enhanced_normalize_input

    # Dans la section de patch des m√©thodes, ajouter :
    AIModel._search_clients = _search_client  # Utiliser le nom correct de la fonction d√©finie
    AIModel._get_available_categories = _get_available_categories
    AIModel._get_available_models = _get_available_models

    return AIModel 

    def _handle_completion(self, message):
        """
        G√®re la compl√©tion d'un document.
        """
        try:
            # Obtenir les informations du formulaire
            form_info = self.current_context.get("form_info", [])
            
            if not form_info:
                return "Vous n'avez pas encore fourni d'informations. Veuillez d'abord me donner les informations n√©cessaires."
            
            # Convertir les informations du formulaire en variables
            variables = self._convert_form_info_to_variables(form_info)
            
            # Obtenir le mod√®le et la cat√©gorie
            category = self.current_context.get("category")
            model = self.current_context.get("model")
            
            if not category or not model:
                return "Je ne peux pas compl√©ter le document car je n'ai pas toutes les informations n√©cessaires. Veuillez r√©essayer depuis le d√©but."
            
            # Obtenir le chemin du mod√®le
            model_path = self.get_model_path(category, model)
            if not model_path:
                return "Je ne trouve pas le mod√®le sp√©cifi√©. Veuillez r√©essayer avec un autre mod√®le."
            
            try:
                # Lire le mod√®le
                with open(model_path, 'r', encoding='utf-8') as f:
                    template_content = f.read()
                
                # Remplacer les variables
                final_content = template_content
                for var_name, value in variables.items():
                    # Rechercher les marqueurs de la forme <<var_name>>
                    final_content = final_content.replace(f"<<{var_name}>>", value)
                
                # Enregistrer le document compl√©t√©
                output_filename = f"filled_{model}"
                output_path = os.path.join(self.models_path, category, output_filename)
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(final_content)
                
                # Mettre √† jour le contexte
                self.current_context["state"] = "initial"
                self.current_context["last_action"] = "document_completed"
                self.current_context["completed_document"] = output_path
                
                return f"""‚úÖ Document compl√©t√© avec succ√®s !

Le document a √©t√© enregistr√© sous : {output_path}

Souhaitez-vous :
1Ô∏è‚É£ Ouvrir le document maintenant
2Ô∏è‚É£ Cr√©er un autre document
3Ô∏è‚É£ Terminer"""
                
            except Exception as e:
                logger.error(f"Erreur lors de la compl√©tion du document: {e}")
                logger.error(traceback.format_exc())
                return "Une erreur s'est produite lors de la compl√©tion du document. Veuillez r√©essayer."
            
        except Exception as e:
            logger.error(f"Erreur dans _handle_completion: {e}")
            logger.error(traceback.format_exc())
            return "Une erreur s'est produite. Veuillez r√©essayer."

    def _show_available_categories(self):
        """
        Affiche les cat√©gories disponibles en utilisant _get_available_categories.
        """
        try:
            # Obtenir les cat√©gories disponibles
            categories = self._get_available_categories()
            
            if not categories:
                return """‚ùå Je n'ai trouv√© aucune cat√©gorie de documents.
                
Veuillez contacter l'administrateur syst√®me."""
            
            # Construire le message de r√©ponse
            response = "üìÇ Voici les cat√©gories de documents disponibles :\n\n"
            for i, category in enumerate(categories, 1):
                response += f"{i}Ô∏è‚É£ {category}\n"
            
            response += "\nVeuillez choisir une cat√©gorie en tapant son num√©ro ou son nom."
            
            # Mettre √† jour le contexte
            self.current_context["state"] = "choosing_category"
            self.current_context["last_action"] = "afficher_categories"
            self.current_context["available_categories"] = categories
            
            return response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'affichage des cat√©gories: {e}")
            logger.error(traceback.format_exc())
            return """‚ùå Une erreur s'est produite lors de la r√©cup√©ration des cat√©gories.
            
Veuillez r√©essayer ou contacter l'administrateur syst√®me."""